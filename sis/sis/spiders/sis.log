2018-12-02 00:59:20 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 00:59:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 00:59:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 00:59:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 00:59:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 00:59:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 00:59:20 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 00:59:20 [scrapy.core.engine] INFO: Spider opened
2018-12-02 00:59:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 00:59:20 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 00:59:20 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 00:59:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76> (referer: None)
2018-12-02 00:59:26 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76###> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-12-02 00:59:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 00:59:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325322&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 00:59:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325322&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '排骨小青年人瘦屌大又硬出租房玩操身材修长马尾辫小女友边干边手机拍体位玩的多插的猛射完还用手玩弄阴唇',
 'picture': '排骨小青年人瘦屌大又硬出租房玩操身材修长马尾辫小女友边干边手机拍体位玩的多插的猛射完还用手玩弄阴唇',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166152'}
2018-12-02 00:59:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325323&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 00:59:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325323&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '豪华约炮房很有情调的激情男女啪啪穿上透明黑丝连干3炮打炮椅健美球全玩一遍奶大臀肥女友爽的尖叫不止胡言乱语',
 'picture': '豪华约炮房很有情调的激情男女啪啪穿上透明黑丝连干3炮打炮椅健美球全玩一遍奶大臀肥女友爽的尖叫不止胡言乱语',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166153'}
2018-12-02 00:59:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325335&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 00:59:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325335&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '土豪大神酒店和2个身材颜值超正的极品美女模特玩一龙二凤,轮流爆操,最后射给了那个最漂亮奶子又大的美女,国语!',
 'picture': '土豪大神酒店和2个身材颜值超正的极品美女模特玩一龙二凤,轮流爆操,最后射给了那个最漂亮奶子又大的美女,国语!',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166159'}
2018-12-02 01:00:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325336&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:00:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325336&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '风骚漂亮主播玲妹妹灬双人激情一多男女啪啪大秀 多姿势做爱很是淫荡',
 'picture': '风骚漂亮主播玲妹妹灬双人激情一多男女啪啪大秀 多姿势做爱很是淫荡',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166161'}
2018-12-02 01:00:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325339&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:00:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325339&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '紧身牛仔裤爆乳美女酒店被各种姿势激烈爆插高潮不断,正享受高潮带来的快感时被男的趁机狠狠内射了.国语!',
 'picture': '紧身牛仔裤爆乳美女酒店被各种姿势激烈爆插高潮不断,正享受高潮带来的快感时被男的趁机狠狠内射了.国语!',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166167'}
2018-12-02 01:00:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325340&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:00:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325340&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '白皙少妇约啪小钢炮，干柴烈火暴力性爱，口交啪啪多体位抽插爆操，大鸡巴塞嘴里抽搐射精',
 'picture': '白皙少妇约啪小钢炮，干柴烈火暴力性爱，口交啪啪多体位抽插爆操，大鸡巴塞嘴里抽搐射精',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166169'}
2018-12-02 01:00:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325342&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:00:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325342&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '3嫩妹和1男炮友收费大秀 口活啪啪 还互相玩弄彼此 这男的真性福',
 'picture': '3嫩妹和1男炮友收费大秀 口活啪啪 还互相玩弄彼此 这男的真性福',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166170'}
2018-12-02 01:00:20 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 10 pages/min), scraped 7 items (at 7 items/min)
2018-12-02 01:00:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325361&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:00:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325361&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '大閘蟹精品大片約啪東航制服抖音網紅空姐',
 'picture': '大閘蟹精品大片約啪東航制服抖音網紅空姐',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166173'}
2018-12-02 01:00:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325363&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:00:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325363&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': 'KK哥作品雙飛膚白貌美的淘寶模特高清 推女郎李麗莎價值888元的超大尺度視頻',
 'picture': 'KK哥作品雙飛膚白貌美的淘寶模特高清 推女郎李麗莎價值888元的超大尺度視頻',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166177'}
2018-12-02 01:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325365&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:00:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325365&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '阿飛作品酒店啪啪某藝校22歲在讀清純大學美女情趣護士裝',
 'picture': '阿飛作品酒店啪啪某藝校22歲在讀清純大學美女情趣護士裝',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166178'}
2018-12-02 01:00:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325418&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:00:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325418&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '秀人网嫩模龙泽美曦宾馆与土豪援交被干到尖叫[MP4/437MB]',
 'picture': '秀人网嫩模龙泽美曦宾馆与土豪援交被干到尖叫[MP4/437MB]',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166214'}
2018-12-02 01:00:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325419&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:00:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325419&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '颜值不错身材超好短发巨乳美女主播[MP4/590MB]',
 'picture': '颜值不错身材超好短发巨乳美女主播[MP4/590MB]',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166215'}
2018-12-02 01:00:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325421&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:00:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325421&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '淫荡小少妇美女趁老公不在和情人家中啪啪[MP4/342MB]',
 'picture': '淫荡小少妇美女趁老公不在和情人家中啪啪[MP4/342MB]',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166216'}
2018-12-02 01:01:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325422&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325422&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '尤物小仙女豹纹黑丝紧身衣高颜值露脸[MP4/633MB]',
 'picture': '尤物小仙女豹纹黑丝紧身衣高颜值露脸[MP4/633MB]',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166217'}
2018-12-02 01:01:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325423&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:01:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325423&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '与两个漂亮风骚姐妹花直播轮流给口交 黑丝美腿[MP4/363MB]',
 'picture': '与两个漂亮风骚姐妹花直播轮流给口交 黑丝美腿[MP4/363MB]',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166218'}
2018-12-02 01:01:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325476&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:01:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325476&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '金发大奶美女主播豹纹情趣装诱惑跳蛋自慰大秀不要错过',
 'picture': '金发大奶美女主播豹纹情趣装诱惑跳蛋自慰大秀不要错过',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166251'}
2018-12-02 01:01:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325479&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:01:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325479&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '这美女主播有点屌光天化日被狼友指挥到五金店里用剪刀剪断内裤抠逼',
 'picture': '这美女主播有点屌光天化日被狼友指挥到五金店里用剪刀剪断内裤抠逼',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166253'}
2018-12-02 01:01:20 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 10 pages/min), scraped 17 items (at 10 items/min)
2018-12-02 01:01:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325480&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:01:26 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325480&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '明星级性感美女与公司领导酒店偷情时被摄像头暗拍,,女的漂亮男的屌大！',
 'picture': '明星级性感美女与公司领导酒店偷情时被摄像头暗拍,,女的漂亮男的屌大！',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166254'}
2018-12-02 01:01:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325482&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:01:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325482&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '精品视讯系列-极品美女主播各种诱惑大尺度大秀喜欢的不要错过',
 'picture': '精品视讯系列-极品美女主播各种诱惑大尺度大秀喜欢的不要错过',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166255'}
2018-12-02 01:01:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325483&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:01:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325483&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '精品视讯系列-极品美女主播各种诱惑大尺度大秀喜欢的不要错过',
 'picture': '精品视讯系列-极品美女主播各种诱惑大尺度大秀喜欢的不要错过',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166256'}
2018-12-02 01:01:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325636&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:01:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325636&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '无套虐操高跟黑丝美乳大二小情人 妖娆妩媚 风骚淫荡浪叫“太粗好爽啊”',
 'picture': '无套虐操高跟黑丝美乳大二小情人 妖娆妩媚 风骚淫荡浪叫“太粗好爽啊”',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166352'}
2018-12-02 01:01:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325637&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:01:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325637&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '小旅馆偷拍眼镜胖哥和打扮浓艳貌似小姐开房啪啪',
 'picture': '小旅馆偷拍眼镜胖哥和打扮浓艳貌似小姐开房啪啪',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166353'}
2018-12-02 01:02:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325639&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:02:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325639&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '约啪可爱丝袜在校学生妹 开始脱个裤子都害羞 害羞有什么用最后还是抽插爆操',
 'picture': '约啪可爱丝袜在校学生妹 开始脱个裤子都害羞 害羞有什么用最后还是抽插爆操',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166354'}
2018-12-02 01:02:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325640&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:02:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325640&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '非常骚气女主播叶美约炮非主流小哥香水瓶子插BB高潮喷水',
 'picture': '非常骚气女主播叶美约炮非主流小哥香水瓶子插BB高潮喷水',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166355'}
2018-12-02 01:02:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325700&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:02:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325700&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '黑车司机老肥91赵邦贺-真实自拍 网上没流出过的与豪爽东北少妇决战苞米地对白有趣高清无水印原版',
 'picture': '黑车司机老肥91赵邦贺-真实自拍 网上没流出过的与豪爽东北少妇决战苞米地对白有趣高清无水印原版',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166395'}
2018-12-02 01:02:20 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 8 pages/min), scraped 25 items (at 8 items/min)
2018-12-02 01:02:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325701&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:02:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325701&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '91新人Dr哥（改名模特女郎）第十部-长腿黑丝海拔超高模特 高颜值极品身材参加完车展半推半就上了她1080P高清无水印',
 'picture': '91新人Dr哥（改名模特女郎）第十部-长腿黑丝海拔超高模特 高颜值极品身材参加完车展半推半就上了她1080P高清无水印',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166396'}
2018-12-02 01:02:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325748&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:02:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325748&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': 'SEX哥原創：175高挑在校淘寶腿模第2部 美腿絲足銷魂浪叫',
 'picture': 'SEX哥原創：175高挑在校淘寶腿模第2部 美腿絲足銷魂浪叫',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166436'}
2018-12-02 01:02:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325760&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:02:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325760&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '超美女神進階版關之琳 白絲高跟從門邊幹到床上',
 'picture': '超美女神進階版關之琳 白絲高跟從門邊幹到床上',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166448'}
2018-12-02 01:02:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325768&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:02:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325768&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '秀人網嫩模艾粟粟3P 沙發調情玩屌扣穴 左舔右擼女上位啪啪第1季',
 'picture': '秀人網嫩模艾粟粟3P 沙發調情玩屌扣穴 左舔右擼女上位啪啪第1季',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166456'}
2018-12-02 01:02:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325775&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:02:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325775&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '押尾貓黑絲女僕裝白嫩美臀無套後入／領導大叔開房啪啪巨乳良家情婦',
 'picture': '押尾貓黑絲女僕裝白嫩美臀無套後入／領導大叔開房啪啪巨乳良家情婦',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166462'}
2018-12-02 01:02:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325805&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:02:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325805&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '十六岁大奶子姐姐带刚成年弟弟直播操逼各种嗨弟弟的JJ还没长熟就被摧残',
 'picture': '十六岁大奶子姐姐带刚成年弟弟直播操逼各种嗨弟弟的JJ还没长熟就被摧残',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166483'}
2018-12-02 01:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325808&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:02:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325808&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '美女主播身材娇小逼毛旺和男友互舔掰逼无套爆操卖力直播国语对话',
 'picture': '美女主播身材娇小逼毛旺和男友互舔掰逼无套爆操卖力直播国语对话',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166484'}
2018-12-02 01:03:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325820&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:03:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325820&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '极品白嫩美女喜欢观音坐莲主动上位操一线逼密不通风真是好逼',
 'picture': '极品白嫩美女喜欢观音坐莲主动上位操一线逼密不通风真是好逼',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166492'}
2018-12-02 01:03:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325823&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:03:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325823&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '豪华套房皮肤白嫩的天然豪乳吊带裙妹子与男友开房造爱口活挺好屁股白又肥',
 'picture': '豪华套房皮肤白嫩的天然豪乳吊带裙妹子与男友开房造爱口活挺好屁股白又肥',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166494'}
2018-12-02 01:03:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325846&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:03:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325846&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '高颜值高收入夫妻也来黄播为哪般露脸口爆国语对白有精彩',
 'picture': '高颜值高收入夫妻也来黄播为哪般露脸口爆国语对白有精彩',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166513'}
2018-12-02 01:03:20 [scrapy.extensions.logstats] INFO: Crawled 38 pages (at 10 pages/min), scraped 35 items (at 10 items/min)
2018-12-02 01:03:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325874&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:03:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=10325874&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:03:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325875&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:03:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325875&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '皮肤白嫩,奶子细腻柔软',
 'picture': '皮肤白嫩,奶子细腻柔软',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166564'}
2018-12-02 01:03:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325876&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:03:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325876&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '漂亮模特被攝影師潛規則粉嫩美穴任意玩口交操逼露臉拍攝',
 'picture': '漂亮模特被攝影師潛規則粉嫩美穴任意玩口交操逼露臉拍攝',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166565'}
2018-12-02 01:03:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325877&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:03:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325877&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '皮肤白嫩身材性感的超漂亮美女被胖男友连扣带操干的高潮不断',
 'picture': '皮肤白嫩身材性感的超漂亮美女被胖男友连扣带操干的高潮不断',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166566'}
2018-12-02 01:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325881&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:03:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325881&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '骗说 我想你了 还担心被听出来',
 'picture': '骗说 我想你了 还担心被听出来',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166567'}
2018-12-02 01:03:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325921&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:03:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325921&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '清纯漂亮的卫校美女酒店被大鸡巴干的高潮来临嗷嗷叫,高呼：舒服,好舒服',
 'picture': '清纯漂亮的卫校美女酒店被大鸡巴干的高潮来临嗷嗷叫,高呼：舒服,好舒服',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166576'}
2018-12-02 01:04:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325925&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325925&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '91新人大屌哥露脸与大学生兼职妹子激情啪啪最后给鸡巴拍照留念',
 'picture': '91新人大屌哥露脸与大学生兼职妹子激情啪啪最后给鸡巴拍照留念',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166577'}
2018-12-02 01:04:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325930&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:04:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325930&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '轰动一时的台湾棒球啦啦队大学美女与男友自拍视频,分手后被曝出完整版',
 'picture': '轰动一时的台湾棒球啦啦队大学美女与男友自拍视频,分手后被曝出完整版',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166580'}
2018-12-02 01:04:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325931&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:04:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325931&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '晚上吃完宵夜和刚破处没多久的技校女友回宿舍啪啪没有戴套不敢内射',
 'picture': '晚上吃完宵夜和刚破处没多久的技校女友回宿舍啪啪没有戴套不敢内射',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166581'}
2018-12-02 01:04:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325932&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:04:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325932&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '小鲜肉男主播直播时网友要求他当着老婆面操双胞胎小姨子',
 'picture': '小鲜肉男主播直播时网友要求他当着老婆面操双胞胎小姨子',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166582'}
2018-12-02 01:04:20 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 10 pages/min), scraped 44 items (at 9 items/min)
2018-12-02 01:04:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=479> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:04:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=506> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:04:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=444> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:04:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=506&filter=0&orderby=lastpost&ascdesc=DESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506)
2018-12-02 01:05:20 [scrapy.extensions.logstats] INFO: Crawled 52 pages (at 4 pages/min), scraped 44 items (at 0 items/min)
2018-12-02 01:05:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506)
2018-12-02 01:05:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4520226&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Dlastpost%26amp%3Bascdesc%3DDESC&page=9> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&filter=0&orderby=lastpost&ascdesc=DESC)
2018-12-02 01:05:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4520226&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Dlastpost%26amp%3Bascdesc%3DDESC&page=9> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&filter=0&orderby=lastpost&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:05:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=7> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:05:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=7> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:05:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:05:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:05:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:05:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:05:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:05:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:05:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:05:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:06:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:06:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:06:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:06:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:06:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:06:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548780&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:06:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=16> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:06:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=16> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:06:20 [scrapy.extensions.logstats] INFO: Crawled 63 pages (at 11 pages/min), scraped 44 items (at 0 items/min)
2018-12-02 01:06:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:06:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:06:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:06:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:06:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:06:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:06:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:06:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:06:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:06:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:06:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:06:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:07:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:07:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4548781&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:07:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4552131&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:07:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4552131&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4552131&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4552131&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:07:20 [scrapy.extensions.logstats] INFO: Crawled 72 pages (at 9 pages/min), scraped 44 items (at 0 items/min)
2018-12-02 01:07:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4552131&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:07:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4552131&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:07:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4552131&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:07:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4552131&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:07:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4556029&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:07:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4556029&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:07:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4556029&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:07:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4556029&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:07:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4556029&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:07:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4556029&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:07:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4556029&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:07:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4556029&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:07:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4556029&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:07:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4556029&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=35> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:08:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=35> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:08:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:08:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:08:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:08:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:08:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:08:20 [scrapy.extensions.logstats] INFO: Crawled 83 pages (at 11 pages/min), scraped 44 items (at 0 items/min)
2018-12-02 01:08:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:08:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:08:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:08:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:08:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:08:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:08:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:08:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4558312&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:08:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=7> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:08:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=7> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:08:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:08:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:08:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:08:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:09:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:09:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:09:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:09:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:09:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:09:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:09:20 [scrapy.extensions.logstats] INFO: Crawled 93 pages (at 10 pages/min), scraped 44 items (at 0 items/min)
2018-12-02 01:09:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:09:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:09:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:09:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4563115&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:09:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4574889&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:09:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4574889&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:09:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4574889&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:09:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4574889&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:10:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4574889&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:10:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4574889&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:10:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4574889&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:10:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4574889&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:10:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4583472&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:10:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4583472&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:10:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4583472&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:10:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4583472&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:10:20 [scrapy.extensions.logstats] INFO: Crawled 101 pages (at 8 pages/min), scraped 44 items (at 0 items/min)
2018-12-02 01:10:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4583472&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:10:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4583472&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:11:20 [scrapy.extensions.logstats] INFO: Crawled 102 pages (at 1 pages/min), scraped 44 items (at 0 items/min)
2018-12-02 01:12:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4583472&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:12:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4583472&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:12:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4583472&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:12:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4583472&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:12:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4583472&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:12:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4583472&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:12:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4584221&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:12:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4584221&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:12:20 [scrapy.extensions.logstats] INFO: Crawled 106 pages (at 4 pages/min), scraped 44 items (at 0 items/min)
2018-12-02 01:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4584221&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:12:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4584221&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:12:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4584221&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:12:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4584221&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:12:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4584221&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:12:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4584221&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:12:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4584221&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:12:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4584221&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:12:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4584221&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:12:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4584221&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 34, in parse_detail
    item['torrent'] = response.xpath("//dl[@class='t_attachlist']/dt/a[2]/@href").extract()[0]
IndexError: list index out of range
2018-12-02 01:12:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4610337&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:12:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4610337&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:13:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4610337&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:13:03 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 01:13:03 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 01:13:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4610337&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:13:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=4610337&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
2018-12-02 01:13:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=4610337&extra=page%3D1%26amp%3Bfilter%3D0%26amp%3Borderby%3Ddateline%26amp%3Bascdesc%3DDESC&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=506&&filter=0&orderby=dateline&ascdesc=DESC)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 25, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:13:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 54662,
 'downloader/request_count': 114,
 'downloader/request_method_count/GET': 114,
 'downloader/response_bytes': 1250544,
 'downloader/response_count': 114,
 'downloader/response_status_count/200': 113,
 'downloader/response_status_count/404': 1,
 'dupefilter/filtered': 592,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 12, 1, 17, 13, 8, 48814),
 'item_scraped_count': 44,
 'log_count/DEBUG': 160,
 'log_count/ERROR': 62,
 'log_count/INFO': 21,
 'request_depth_max': 3,
 'response_received_count': 114,
 'scheduler/dequeued': 113,
 'scheduler/dequeued/memory': 113,
 'scheduler/enqueued': 706,
 'scheduler/enqueued/memory': 706,
 'spider_exceptions/IndexError': 62,
 'start_time': datetime.datetime(2018, 12, 1, 16, 59, 20, 580182)}
2018-12-02 01:13:08 [scrapy.core.engine] INFO: Spider closed (shutdown)
2018-12-02 01:21:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 01:21:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 01:21:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 01:21:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 01:21:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 01:21:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 01:21:11 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 01:21:11 [scrapy.core.engine] INFO: Spider opened
2018-12-02 01:21:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 01:21:11 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 01:21:11 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 01:21:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76> (referer: None)
2018-12-02 01:21:19 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76###> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-12-02 01:21:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:21:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325322&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:21:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325322&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '排骨小青年人瘦屌大又硬出租房玩操身材修长马尾辫小女友边干边手机拍体位玩的多插的猛射完还用手玩弄阴唇',
 'picture': '排骨小青年人瘦屌大又硬出租房玩操身材修长马尾辫小女友边干边手机拍体位玩的多插的猛射完还用手玩弄阴唇',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166152'}
2018-12-02 01:21:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=YCyFun> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=YCyFun> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:21:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=YCyFun)
2018-12-02 01:21:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=YCyFun)
2018-12-02 01:22:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=H6ygmE> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636)
2018-12-02 01:22:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=95X9PG> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183)
2018-12-02 01:22:11 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 10 pages/min), scraped 1 items (at 1 items/min)
2018-12-02 01:22:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=MoDka5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=H6ygmE)
2018-12-02 01:22:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=5cRNCt> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=95X9PG)
2018-12-02 01:22:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=23G8aC> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=MoDka5)
2018-12-02 01:22:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=f0HXIc> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=5cRNCt)
2018-12-02 01:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=QRtfXI> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=23G8aC)
2018-12-02 01:22:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=tS5p4W> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=f0HXIc)
2018-12-02 01:22:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=anuJUE> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=QRtfXI)
2018-12-02 01:22:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=2Di60d> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=tS5p4W)
2018-12-02 01:23:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=oEabJX> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=anuJUE)
2018-12-02 01:23:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=4DlH5l> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=636&sid=2Di60d)
2018-12-02 01:23:11 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 10 pages/min), scraped 1 items (at 0 items/min)
2018-12-02 01:23:19 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 01:23:19 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 01:23:19 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 01:23:19 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=2k14Dq. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2018-12-02 01:23:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=183&sid=2k14Dq> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>, <twisted.python.failure.Failure twisted.web.http._DataLoss: Chunked decoder in 'BODY' state, still expecting more data to get to 'FINISHED' state.>]
2018-12-02 01:23:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 1,
 'downloader/request_bytes': 8599,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 251535,
 'downloader/response_count': 20,
 'downloader/response_status_count/200': 19,
 'downloader/response_status_count/404': 1,
 'dupefilter/filtered': 2439,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 12, 1, 17, 23, 19, 873207),
 'item_scraped_count': 1,
 'log_count/DEBUG': 24,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 10,
 'response_received_count': 20,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 1,
 'scheduler/dequeued': 20,
 'scheduler/dequeued/memory': 20,
 'scheduler/enqueued': 733,
 'scheduler/enqueued/memory': 733,
 'start_time': datetime.datetime(2018, 12, 1, 17, 21, 11, 137943)}
2018-12-02 01:23:19 [scrapy.core.engine] INFO: Spider closed (shutdown)
2018-12-02 01:23:27 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 01:23:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 01:23:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 01:23:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 01:23:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 01:23:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 01:23:27 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 01:23:27 [scrapy.core.engine] INFO: Spider opened
2018-12-02 01:23:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 01:23:27 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 01:23:28 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 01:23:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76> (referer: None)
2018-12-02 01:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:23:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 28, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325322&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:23:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325322&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '排骨小青年人瘦屌大又硬出租房玩操身材修长马尾辫小女友边干边手机拍体位玩的多插的猛射完还用手玩弄阴唇',
 'picture': '排骨小青年人瘦屌大又硬出租房玩操身材修长马尾辫小女友边干边手机拍体位玩的多插的猛射完还用手玩弄阴唇',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166152'}
2018-12-02 01:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325323&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:23:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325323&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '豪华约炮房很有情调的激情男女啪啪穿上透明黑丝连干3炮打炮椅健美球全玩一遍奶大臀肥女友爽的尖叫不止胡言乱语',
 'picture': '豪华约炮房很有情调的激情男女啪啪穿上透明黑丝连干3炮打炮椅健美球全玩一遍奶大臀肥女友爽的尖叫不止胡言乱语',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166153'}
2018-12-02 01:24:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325335&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:24:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325335&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '土豪大神酒店和2个身材颜值超正的极品美女模特玩一龙二凤,轮流爆操,最后射给了那个最漂亮奶子又大的美女,国语!',
 'picture': '土豪大神酒店和2个身材颜值超正的极品美女模特玩一龙二凤,轮流爆操,最后射给了那个最漂亮奶子又大的美女,国语!',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166159'}
2018-12-02 01:24:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325336&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:24:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325336&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '风骚漂亮主播玲妹妹灬双人激情一多男女啪啪大秀 多姿势做爱很是淫荡',
 'picture': '风骚漂亮主播玲妹妹灬双人激情一多男女啪啪大秀 多姿势做爱很是淫荡',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166161'}
2018-12-02 01:24:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325339&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:24:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325339&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '紧身牛仔裤爆乳美女酒店被各种姿势激烈爆插高潮不断,正享受高潮带来的快感时被男的趁机狠狠内射了.国语!',
 'picture': '紧身牛仔裤爆乳美女酒店被各种姿势激烈爆插高潮不断,正享受高潮带来的快感时被男的趁机狠狠内射了.国语!',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166167'}
2018-12-02 01:24:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325340&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:24:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325340&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '白皙少妇约啪小钢炮，干柴烈火暴力性爱，口交啪啪多体位抽插爆操，大鸡巴塞嘴里抽搐射精',
 'picture': '白皙少妇约啪小钢炮，干柴烈火暴力性爱，口交啪啪多体位抽插爆操，大鸡巴塞嘴里抽搐射精',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166169'}
2018-12-02 01:24:27 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 6 items (at 6 items/min)
2018-12-02 01:24:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325342&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:24:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325342&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '3嫩妹和1男炮友收费大秀 口活啪啪 还互相玩弄彼此 这男的真性福',
 'picture': '3嫩妹和1男炮友收费大秀 口活啪啪 还互相玩弄彼此 这男的真性福',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166170'}
2018-12-02 01:24:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325361&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:24:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325361&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '大閘蟹精品大片約啪東航制服抖音網紅空姐',
 'picture': '大閘蟹精品大片約啪東航制服抖音網紅空姐',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166173'}
2018-12-02 01:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325363&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:24:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325363&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': 'KK哥作品雙飛膚白貌美的淘寶模特高清 推女郎李麗莎價值888元的超大尺度視頻',
 'picture': 'KK哥作品雙飛膚白貌美的淘寶模特高清 推女郎李麗莎價值888元的超大尺度視頻',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166177'}
2018-12-02 01:24:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325365&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:24:46 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325365&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '阿飛作品酒店啪啪某藝校22歲在讀清純大學美女情趣護士裝',
 'picture': '阿飛作品酒店啪啪某藝校22歲在讀清純大學美女情趣護士裝',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166178'}
2018-12-02 01:24:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325418&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:24:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325418&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '秀人网嫩模龙泽美曦宾馆与土豪援交被干到尖叫[MP4/437MB]',
 'picture': '秀人网嫩模龙泽美曦宾馆与土豪援交被干到尖叫[MP4/437MB]',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166214'}
2018-12-02 01:25:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325419&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:25:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325419&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '颜值不错身材超好短发巨乳美女主播[MP4/590MB]',
 'picture': '颜值不错身材超好短发巨乳美女主播[MP4/590MB]',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166215'}
2018-12-02 01:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325421&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:25:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325421&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '淫荡小少妇美女趁老公不在和情人家中啪啪[MP4/342MB]',
 'picture': '淫荡小少妇美女趁老公不在和情人家中啪啪[MP4/342MB]',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166216'}
2018-12-02 01:25:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325422&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:25:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325422&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '尤物小仙女豹纹黑丝紧身衣高颜值露脸[MP4/633MB]',
 'picture': '尤物小仙女豹纹黑丝紧身衣高颜值露脸[MP4/633MB]',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166217'}
2018-12-02 01:25:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325423&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:25:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325423&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '与两个漂亮风骚姐妹花直播轮流给口交 黑丝美腿[MP4/363MB]',
 'picture': '与两个漂亮风骚姐妹花直播轮流给口交 黑丝美腿[MP4/363MB]',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166218'}
2018-12-02 01:25:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325476&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:25:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325476&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '金发大奶美女主播豹纹情趣装诱惑跳蛋自慰大秀不要错过',
 'picture': '金发大奶美女主播豹纹情趣装诱惑跳蛋自慰大秀不要错过',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166251'}
2018-12-02 01:25:27 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 10 pages/min), scraped 16 items (at 10 items/min)
2018-12-02 01:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325479&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:25:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325479&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '这美女主播有点屌光天化日被狼友指挥到五金店里用剪刀剪断内裤抠逼',
 'picture': '这美女主播有点屌光天化日被狼友指挥到五金店里用剪刀剪断内裤抠逼',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166253'}
2018-12-02 01:25:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325480&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:25:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325480&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '明星级性感美女与公司领导酒店偷情时被摄像头暗拍,,女的漂亮男的屌大！',
 'picture': '明星级性感美女与公司领导酒店偷情时被摄像头暗拍,,女的漂亮男的屌大！',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166254'}
2018-12-02 01:25:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325482&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:25:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325482&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '精品视讯系列-极品美女主播各种诱惑大尺度大秀喜欢的不要错过',
 'picture': '精品视讯系列-极品美女主播各种诱惑大尺度大秀喜欢的不要错过',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166255'}
2018-12-02 01:25:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325483&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:25:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325483&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '精品视讯系列-极品美女主播各种诱惑大尺度大秀喜欢的不要错过',
 'picture': '精品视讯系列-极品美女主播各种诱惑大尺度大秀喜欢的不要错过',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166256'}
2018-12-02 01:25:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325636&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:25:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325636&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '无套虐操高跟黑丝美乳大二小情人 妖娆妩媚 风骚淫荡浪叫“太粗好爽啊”',
 'picture': '无套虐操高跟黑丝美乳大二小情人 妖娆妩媚 风骚淫荡浪叫“太粗好爽啊”',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166352'}
2018-12-02 01:26:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325637&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:26:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325637&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '小旅馆偷拍眼镜胖哥和打扮浓艳貌似小姐开房啪啪',
 'picture': '小旅馆偷拍眼镜胖哥和打扮浓艳貌似小姐开房啪啪',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166353'}
2018-12-02 01:26:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325639&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:26:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325639&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '约啪可爱丝袜在校学生妹 开始脱个裤子都害羞 害羞有什么用最后还是抽插爆操',
 'picture': '约啪可爱丝袜在校学生妹 开始脱个裤子都害羞 害羞有什么用最后还是抽插爆操',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166354'}
2018-12-02 01:26:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325640&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:26:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325640&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '非常骚气女主播叶美约炮非主流小哥香水瓶子插BB高潮喷水',
 'picture': '非常骚气女主播叶美约炮非主流小哥香水瓶子插BB高潮喷水',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166355'}
2018-12-02 01:26:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325700&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:26:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325700&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '黑车司机老肥91赵邦贺-真实自拍 网上没流出过的与豪爽东北少妇决战苞米地对白有趣高清无水印原版',
 'picture': '黑车司机老肥91赵邦贺-真实自拍 网上没流出过的与豪爽东北少妇决战苞米地对白有趣高清无水印原版',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166395'}
2018-12-02 01:26:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325701&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:26:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325701&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '91新人Dr哥（改名模特女郎）第十部-长腿黑丝海拔超高模特 高颜值极品身材参加完车展半推半就上了她1080P高清无水印',
 'picture': '91新人Dr哥（改名模特女郎）第十部-长腿黑丝海拔超高模特 高颜值极品身材参加完车展半推半就上了她1080P高清无水印',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166396'}
2018-12-02 01:26:27 [scrapy.extensions.logstats] INFO: Crawled 29 pages (at 10 pages/min), scraped 26 items (at 10 items/min)
2018-12-02 01:26:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325748&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:26:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325748&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': 'SEX哥原創：175高挑在校淘寶腿模第2部 美腿絲足銷魂浪叫',
 'picture': 'SEX哥原創：175高挑在校淘寶腿模第2部 美腿絲足銷魂浪叫',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166436'}
2018-12-02 01:26:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325760&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:26:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325760&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '超美女神進階版關之琳 白絲高跟從門邊幹到床上',
 'picture': '超美女神進階版關之琳 白絲高跟從門邊幹到床上',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166448'}
2018-12-02 01:26:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325768&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:26:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325768&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '秀人網嫩模艾粟粟3P 沙發調情玩屌扣穴 左舔右擼女上位啪啪第1季',
 'picture': '秀人網嫩模艾粟粟3P 沙發調情玩屌扣穴 左舔右擼女上位啪啪第1季',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166456'}
2018-12-02 01:26:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325775&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:26:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325775&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '押尾貓黑絲女僕裝白嫩美臀無套後入／領導大叔開房啪啪巨乳良家情婦',
 'picture': '押尾貓黑絲女僕裝白嫩美臀無套後入／領導大叔開房啪啪巨乳良家情婦',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166462'}
2018-12-02 01:27:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325805&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:27:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325805&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '十六岁大奶子姐姐带刚成年弟弟直播操逼各种嗨弟弟的JJ还没长熟就被摧残',
 'picture': '十六岁大奶子姐姐带刚成年弟弟直播操逼各种嗨弟弟的JJ还没长熟就被摧残',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166483'}
2018-12-02 01:27:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325808&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:27:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325808&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '美女主播身材娇小逼毛旺和男友互舔掰逼无套爆操卖力直播国语对话',
 'picture': '美女主播身材娇小逼毛旺和男友互舔掰逼无套爆操卖力直播国语对话',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166484'}
2018-12-02 01:27:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325820&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:27:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325820&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '极品白嫩美女喜欢观音坐莲主动上位操一线逼密不通风真是好逼',
 'picture': '极品白嫩美女喜欢观音坐莲主动上位操一线逼密不通风真是好逼',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166492'}
2018-12-02 01:27:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325823&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:27:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325823&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '豪华套房皮肤白嫩的天然豪乳吊带裙妹子与男友开房造爱口活挺好屁股白又肥',
 'picture': '豪华套房皮肤白嫩的天然豪乳吊带裙妹子与男友开房造爱口活挺好屁股白又肥',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166494'}
2018-12-02 01:27:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325846&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:27:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325846&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '高颜值高收入夫妻也来黄播为哪般露脸口爆国语对白有精彩',
 'picture': '高颜值高收入夫妻也来黄播为哪般露脸口爆国语对白有精彩',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166513'}
2018-12-02 01:27:27 [scrapy.extensions.logstats] INFO: Crawled 38 pages (at 9 pages/min), scraped 35 items (at 9 items/min)
2018-12-02 01:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325874&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:27:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325874&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '女主吹箫',
 'picture': '女主吹箫',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166563'}
2018-12-02 01:27:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325875&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:27:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325875&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '皮肤白嫩,奶子细腻柔软',
 'picture': '皮肤白嫩,奶子细腻柔软',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166564'}
2018-12-02 01:27:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325876&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:27:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325876&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '漂亮模特被攝影師潛規則粉嫩美穴任意玩口交操逼露臉拍攝',
 'picture': '漂亮模特被攝影師潛規則粉嫩美穴任意玩口交操逼露臉拍攝',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166565'}
2018-12-02 01:27:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325877&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:27:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325877&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '皮肤白嫩身材性感的超漂亮美女被胖男友连扣带操干的高潮不断',
 'picture': '皮肤白嫩身材性感的超漂亮美女被胖男友连扣带操干的高潮不断',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166566'}
2018-12-02 01:27:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325881&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:27:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325881&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '骗说 我想你了 还担心被听出来',
 'picture': '骗说 我想你了 还担心被听出来',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166567'}
2018-12-02 01:27:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325921&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:27:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325921&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '清纯漂亮的卫校美女酒店被大鸡巴干的高潮来临嗷嗷叫,高呼：舒服,好舒服',
 'picture': '清纯漂亮的卫校美女酒店被大鸡巴干的高潮来临嗷嗷叫,高呼：舒服,好舒服',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166576'}
2018-12-02 01:28:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325925&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325925&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '91新人大屌哥露脸与大学生兼职妹子激情啪啪最后给鸡巴拍照留念',
 'picture': '91新人大屌哥露脸与大学生兼职妹子激情啪啪最后给鸡巴拍照留念',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166577'}
2018-12-02 01:28:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325930&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:28:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325930&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '轰动一时的台湾棒球啦啦队大学美女与男友自拍视频,分手后被曝出完整版',
 'picture': '轰动一时的台湾棒球啦啦队大学美女与男友自拍视频,分手后被曝出完整版',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166580'}
2018-12-02 01:28:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325931&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:28:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325931&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '晚上吃完宵夜和刚破处没多久的技校女友回宿舍啪啪没有戴套不敢内射',
 'picture': '晚上吃完宵夜和刚破处没多久的技校女友回宿舍啪啪没有戴套不敢内射',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166581'}
2018-12-02 01:28:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325932&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:28:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325932&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '小鲜肉男主播直播时网友要求他当着老婆面操双胞胎小姨子',
 'picture': '小鲜肉男主播直播时网友要求他当着老婆面操双胞胎小姨子',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166582'}
2018-12-02 01:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76&special=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:28:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76&special=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 28, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:28:27 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 11 pages/min), scraped 45 items (at 10 items/min)
2018-12-02 01:28:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76&special=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:28:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76&special=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 28, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:28:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76&special=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:28:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76&special=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 28, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:28:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76&special=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:28:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76&special=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 28, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:28:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76&special=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:28:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76&special=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 28, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:28:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76&special=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:28:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76&special=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 28, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:28:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 01:28:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 24050,
 'downloader/request_count': 54,
 'downloader/request_method_count/GET': 54,
 'downloader/response_bytes': 522581,
 'downloader/response_count': 54,
 'downloader/response_status_count/200': 53,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 1, 17, 28, 53, 602484),
 'item_scraped_count': 45,
 'log_count/DEBUG': 100,
 'log_count/ERROR': 7,
 'log_count/INFO': 12,
 'request_depth_max': 1,
 'response_received_count': 54,
 'scheduler/dequeued': 53,
 'scheduler/dequeued/memory': 53,
 'scheduler/enqueued': 53,
 'scheduler/enqueued/memory': 53,
 'spider_exceptions/IndexError': 7,
 'start_time': datetime.datetime(2018, 12, 1, 17, 23, 27, 917314)}
2018-12-02 01:28:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 01:44:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 01:44:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 01:44:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 01:44:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 01:44:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 01:44:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 01:44:47 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 01:44:47 [scrapy.core.engine] INFO: Spider opened
2018-12-02 01:44:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 01:44:47 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 01:44:47 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 01:44:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76> (referer: None)
2018-12-02 01:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:45:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325322&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:45:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325323&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:45:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325335&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:45:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325336&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:45:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325339&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:45:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325340&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325342&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:45:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325361&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:45:47 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 01:45:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325363&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:45:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325365&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:46:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325418&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:46:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325419&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:46:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325421&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:46:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325422&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:46:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325423&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:46:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325476&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:46:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325479&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:46:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325480&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:46:47 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 01:46:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325482&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:46:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325483&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:47:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325636&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:47:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325637&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:47:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325639&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:47:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325640&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:47:25 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 01:47:25 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 01:47:27 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 01:48:08 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 01:48:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 01:48:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 01:48:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 01:48:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 01:48:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 01:48:08 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 01:48:08 [scrapy.core.engine] INFO: Spider opened
2018-12-02 01:48:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 01:48:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 01:48:09 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 01:48:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76> (referer: None)
2018-12-02 01:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:48:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325322&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:48:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325323&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:48:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325335&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:48:41 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 01:48:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325336&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:48:41 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 01:48:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2898,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 62892,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 6,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 12, 1, 17, 48, 41, 150092),
 'log_count/DEBUG': 8,
 'log_count/INFO': 8,
 'request_depth_max': 1,
 'response_received_count': 7,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 53,
 'scheduler/enqueued/memory': 53,
 'start_time': datetime.datetime(2018, 12, 1, 17, 48, 8, 853877)}
2018-12-02 01:48:41 [scrapy.core.engine] INFO: Spider closed (shutdown)
2018-12-02 01:48:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 01:48:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 01:48:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 01:48:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 01:48:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 01:48:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 01:48:57 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 01:48:57 [scrapy.core.engine] INFO: Spider opened
2018-12-02 01:48:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 01:48:57 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 01:48:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 01:49:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76> (referer: None)
2018-12-02 01:49:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:49:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/post.php?action=newthread&fid=25&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 28, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 01:49:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325322&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:49:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325322&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '排骨小青年人瘦屌大又硬出租房玩操身材修长马尾辫小女友边干边手机拍体位玩的多插的猛射完还用手玩弄阴唇',
 'picture': '排骨小青年人瘦屌大又硬出租房玩操身材修长马尾辫小女友边干边手机拍体位玩的多插的猛射完还用手玩弄阴唇',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166152'}
2018-12-02 01:49:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325323&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:49:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325323&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '豪华约炮房很有情调的激情男女啪啪穿上透明黑丝连干3炮打炮椅健美球全玩一遍奶大臀肥女友爽的尖叫不止胡言乱语',
 'picture': '豪华约炮房很有情调的激情男女啪啪穿上透明黑丝连干3炮打炮椅健美球全玩一遍奶大臀肥女友爽的尖叫不止胡言乱语',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166153'}
2018-12-02 01:49:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325335&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:49:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325335&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '土豪大神酒店和2个身材颜值超正的极品美女模特玩一龙二凤,轮流爆操,最后射给了那个最漂亮奶子又大的美女,国语!',
 'picture': '土豪大神酒店和2个身材颜值超正的极品美女模特玩一龙二凤,轮流爆操,最后射给了那个最漂亮奶子又大的美女,国语!',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166159'}
2018-12-02 01:49:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325336&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:49:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325336&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '风骚漂亮主播玲妹妹灬双人激情一多男女啪啪大秀 多姿势做爱很是淫荡',
 'picture': '风骚漂亮主播玲妹妹灬双人激情一多男女啪啪大秀 多姿势做爱很是淫荡',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166161'}
2018-12-02 01:49:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325339&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:49:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://38.103.161.131/forum/viewthread.php?tid=10325339&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
{'name': '紧身牛仔裤爆乳美女酒店被各种姿势激烈爆插高潮不断,正享受高潮带来的快感时被男的趁机狠狠内射了.国语!',
 'picture': '紧身牛仔裤爆乳美女酒店被各种姿势激烈爆插高潮不断,正享受高潮带来的快感时被男的趁机狠狠内射了.国语!',
 'time': '2018-12-1',
 'torrent': 'attachment.php?aid=3166167'}
2018-12-02 01:49:39 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 01:49:39 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 01:49:39 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 01:49:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 01:49:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 01:49:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 01:49:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 01:49:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 01:49:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 01:49:53 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 01:49:53 [scrapy.core.engine] INFO: Spider opened
2018-12-02 01:49:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 01:49:53 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 01:49:54 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 01:50:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76> (referer: None)
2018-12-02 01:50:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 01:50:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 571,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 15218,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 1, 17, 50, 5, 445389),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 1, 17, 49, 53, 817478)}
2018-12-02 01:50:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 01:51:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 01:51:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 01:51:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 01:51:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 01:51:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 01:51:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 01:51:17 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 01:51:17 [scrapy.core.engine] INFO: Spider opened
2018-12-02 01:51:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 01:51:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 01:51:18 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 01:51:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76> (referer: None)
2018-12-02 01:51:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:51:30 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-12-02 01:51:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=416> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76)
2018-12-02 01:51:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2)
2018-12-02 01:51:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=414> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=416)
2018-12-02 01:51:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=413> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=416)
2018-12-02 01:51:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=412> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=416)
2018-12-02 01:52:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=411> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=416)
2018-12-02 01:52:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=410> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=416)
2018-12-02 01:52:17 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 01:52:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=409> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=416)
2018-12-02 01:52:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=408> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=416)
2018-12-02 01:52:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=407> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=416)
2018-12-02 01:52:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=406> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=408)
2018-12-02 01:52:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=405> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=407)
2018-12-02 01:52:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=404> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=406)
2018-12-02 01:52:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=403> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=405)
2018-12-02 01:53:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=402> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=404)
2018-12-02 01:53:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=401> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=403)
2018-12-02 01:53:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=400> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=402)
2018-12-02 01:53:17 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 01:53:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=399> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=401)
2018-12-02 01:53:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=398> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=400)
2018-12-02 01:53:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=397> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=399)
2018-12-02 01:53:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=396> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=398)
2018-12-02 01:53:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=395> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=397)
2018-12-02 01:53:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=394> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=396)
2018-12-02 01:53:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=393> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=395)
2018-12-02 01:54:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=392> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=394)
2018-12-02 01:54:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=391> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=393)
2018-12-02 01:54:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=390> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=392)
2018-12-02 01:54:17 [scrapy.extensions.logstats] INFO: Crawled 30 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 01:54:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=389> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=391)
2018-12-02 01:54:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=388> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=390)
2018-12-02 01:54:30 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 01:54:30 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 01:54:31 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 02:22:06 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 02:22:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 02:22:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 02:22:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 02:22:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 02:22:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 02:22:06 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 02:22:06 [scrapy.core.engine] INFO: Spider opened
2018-12-02 02:22:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 02:22:06 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 02:22:07 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 02:22:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 02:22:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 02:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2)
2018-12-02 02:22:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3)
2018-12-02 02:22:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=4)
2018-12-02 02:22:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=5)
2018-12-02 02:22:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=7> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=6)
2018-12-02 02:22:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=8> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=7)
2018-12-02 02:23:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=9> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=8)
2018-12-02 02:23:06 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 02:23:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=10> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=9)
2018-12-02 02:23:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=11> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=10)
2018-12-02 02:23:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=12> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=11)
2018-12-02 02:23:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=13> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=12)
2018-12-02 02:23:29 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 02:23:29 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 02:23:29 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 02:23:32 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 02:23:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 02:23:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 02:23:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 02:23:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 02:23:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 02:23:32 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 02:23:32 [scrapy.core.engine] INFO: Spider opened
2018-12-02 02:23:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 02:23:32 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 02:23:32 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 02:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 02:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 02:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2)
2018-12-02 02:24:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3)
2018-12-02 02:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=4)
2018-12-02 02:24:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=5)
2018-12-02 02:24:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=7> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=6)
2018-12-02 02:24:21 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 02:24:21 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 02:24:22 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 02:24:39 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 02:24:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 02:24:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 02:24:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 02:24:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 02:24:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 02:24:39 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 02:24:39 [scrapy.core.engine] INFO: Spider opened
2018-12-02 02:24:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 02:24:39 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 02:24:40 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 02:24:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 02:24:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 02:24:57 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 02:24:57 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 02:24:59 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 02:26:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 02:26:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 02:26:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 02:26:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 02:26:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 02:26:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 02:26:46 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 02:26:46 [scrapy.core.engine] INFO: Spider opened
2018-12-02 02:26:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 02:26:46 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 02:26:46 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 02:26:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 02:26:58 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 02:26:58 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 02:26:59 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 02:27:49 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 02:27:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 02:27:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 02:27:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 02:27:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 02:27:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 02:27:49 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.ImagesPipeline']
2018-12-02 02:27:49 [scrapy.core.engine] INFO: Spider opened
2018-12-02 02:27:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 02:27:49 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 02:27:49 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 02:27:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 02:27:57 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to '38.103.161.131': <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10325932&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
2018-12-02 02:28:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 02:28:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2)
2018-12-02 02:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3)
2018-12-02 02:28:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=4)
2018-12-02 02:28:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=5)
2018-12-02 02:28:28 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 02:28:28 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 02:28:28 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 02:28:28 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=7. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2018-12-02 02:28:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>, <twisted.python.failure.Failure twisted.web.http._DataLoss: Chunked decoder in 'BODY' state, still expecting more data to get to 'FINISHED' state.>]
2018-12-02 02:28:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 1,
 'downloader/request_bytes': 3196,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 92906,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 6,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 12, 1, 18, 28, 28, 853113),
 'log_count/DEBUG': 10,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 272,
 'request_depth_max': 6,
 'response_received_count': 7,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 1,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2018, 12, 1, 18, 27, 49, 437662)}
2018-12-02 02:28:28 [scrapy.core.engine] INFO: Spider closed (shutdown)
2018-12-02 23:21:13 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 23:21:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 23:21:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 23:21:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 23:21:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 23:21:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 23:21:13 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-02 23:21:13 [scrapy.core.engine] INFO: Spider opened
2018-12-02 23:21:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:21:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 23:21:16 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 23:21:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 23:21:41 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to '38.103.161.131': <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
2018-12-02 23:21:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2)
2018-12-02 23:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3)
2018-12-02 23:22:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=4)
2018-12-02 23:22:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=5)
2018-12-02 23:22:13 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:22:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=7> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=6)
2018-12-02 23:22:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=8> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=7)
2018-12-02 23:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=9> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=8)
2018-12-02 23:22:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=10> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=9)
2018-12-02 23:22:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=11> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=10)
2018-12-02 23:22:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=12> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=11)
2018-12-02 23:22:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=13> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=12)
2018-12-02 23:23:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=14> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=13)
2018-12-02 23:23:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=15> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=14)
2018-12-02 23:23:12 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 23:23:12 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 23:23:12 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 23:23:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 23:23:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 23:23:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 23:23:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 23:23:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 23:23:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 23:23:30 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-02 23:23:30 [scrapy.core.engine] INFO: Spider opened
2018-12-02 23:23:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:23:30 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 23:23:31 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 23:23:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 23:23:37 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to '38.103.161.131': <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76>
2018-12-02 23:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:23:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2)
2018-12-02 23:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3)
2018-12-02 23:23:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=5> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=4)
2018-12-02 23:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=6> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=5)
2018-12-02 23:24:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=7> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=6)
2018-12-02 23:24:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=8> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=7)
2018-12-02 23:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=9> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=8)
2018-12-02 23:24:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=10> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=9)
2018-12-02 23:24:30 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=11> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=10)
2018-12-02 23:24:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=12> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=11)
2018-12-02 23:24:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=13> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=12)
2018-12-02 23:24:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=14> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=13)
2018-12-02 23:24:59 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 23:24:59 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 23:25:01 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 23:25:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=15. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2018-12-02 23:25:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>, <twisted.python.failure.Failure twisted.web.http._DataLoss: Chunked decoder in 'BODY' state, still expecting more data to get to 'FINISHED' state.>]
2018-12-02 23:25:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 1,
 'downloader/request_bytes': 6416,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 217426,
 'downloader/response_count': 15,
 'downloader/response_status_count/200': 14,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 12, 2, 15, 25, 1, 93515),
 'log_count/DEBUG': 18,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 634,
 'request_depth_max': 14,
 'response_received_count': 15,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 1,
 'scheduler/dequeued': 15,
 'scheduler/dequeued/memory': 15,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2018, 12, 2, 15, 23, 30, 663761)}
2018-12-02 23:25:01 [scrapy.core.engine] INFO: Spider closed (shutdown)
2018-12-02 23:26:13 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 23:26:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 23:26:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 23:26:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 23:26:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 23:26:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 23:26:14 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-02 23:26:14 [scrapy.core.engine] INFO: Spider opened
2018-12-02 23:26:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:26:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 23:26:23 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 23:26:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 23:26:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:26:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 31, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 23:26:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:26:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10325932&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:26:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10325932&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 31, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 23:26:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2)
2018-12-02 23:27:00 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 23:27:00 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 23:27:00 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 23:27:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10325321&extra=page%3D2%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2018-12-02 23:27:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.internet.error.ConnectError': 1,
 'downloader/request_bytes': 2876,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 56956,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 5,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 12, 2, 15, 27, 0, 833712),
 'log_count/DEBUG': 8,
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'request_depth_max': 3,
 'response_received_count': 6,
 'retry/count': 1,
 'retry/reason_count/twisted.internet.error.ConnectError': 1,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 140,
 'scheduler/enqueued/memory': 140,
 'spider_exceptions/IndexError': 2,
 'start_time': datetime.datetime(2018, 12, 2, 15, 26, 14, 223287)}
2018-12-02 23:27:00 [scrapy.core.engine] INFO: Spider closed (shutdown)
2018-12-02 23:29:35 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 23:29:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 23:29:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 23:29:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 23:29:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 23:29:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 23:29:35 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-02 23:29:35 [scrapy.core.engine] INFO: Spider opened
2018-12-02 23:29:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:29:35 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 23:29:36 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://38.103.161.131/robots.txt> (referer: None)
2018-12-02 23:29:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 23:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:29:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 31, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 23:29:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:29:55 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 23:29:55 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 23:29:56 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 23:30:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 23:30:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 23:30:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 23:30:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 23:30:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 23:30:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 23:30:50 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-02 23:30:50 [scrapy.core.engine] INFO: Spider opened
2018-12-02 23:30:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:30:50 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 23:30:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 23:31:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:31:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 31, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 23:31:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:31:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10325932&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:31:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?viewthread.php?tid=10325932&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 31, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 23:31:24 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 23:31:24 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 23:31:25 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 23:33:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 23:33:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 23:33:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 23:33:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 23:33:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 23:33:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 23:33:55 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-02 23:33:55 [scrapy.core.engine] INFO: Spider opened
2018-12-02 23:33:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:33:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 23:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 23:34:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:34:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 31, in parse_detail
    item['name'] = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-02 23:34:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10325932&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:34:17 [scrapy.core.scraper] ERROR: Error processing {'image_urls': '小鲜肉男主播直播时网友要求他当着老婆面操双胞胎小姨子',
 'name': '小鲜肉男主播直播时网友要求他当着老婆面操双胞胎小姨子',
 'time': '2018-12-1',
 'torrent_url': 'attachment.php?aid=3166582'}
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\pipelines\media.py", line 80, in process_item
    dlist = [self._process_request(r, info) for r in requests]
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\pipelines\media.py", line 80, in <listcomp>
    dlist = [self._process_request(r, info) for r in requests]
  File "D:\PythonWorkSpace\sis\sis\pipelines.py", line 23, in get_media_requests
    yield Request(image_url,meta={'item':item, 'index':item['image_urls'].index(image_url)}) #添加meta是为了下面重命名文件名使用
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\http\request\__init__.py", line 25, in __init__
    self._set_url(url)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\http\request\__init__.py", line 62, in _set_url
    raise ValueError('Missing scheme in request url: %s' % self._url)
ValueError: Missing scheme in request url: %E5%B0%8F
2018-12-02 23:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2)
2018-12-02 23:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326061&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:34:30 [scrapy.core.scraper] ERROR: Error processing {'image_urls': '[MP4/998.90 MB]私房片精选国产自拍合集[20181201]',
 'name': '[MP4/998.90 MB]私房片精选国产自拍合集[20181201]',
 'time': '2018-12-2',
 'torrent_url': 'attachment.php?aid=3166674'}
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\pipelines\media.py", line 80, in process_item
    dlist = [self._process_request(r, info) for r in requests]
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\pipelines\media.py", line 80, in <listcomp>
    dlist = [self._process_request(r, info) for r in requests]
  File "D:\PythonWorkSpace\sis\sis\pipelines.py", line 23, in get_media_requests
    yield Request(image_url,meta={'item':item, 'index':item['image_urls'].index(image_url)}) #添加meta是为了下面重命名文件名使用
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\http\request\__init__.py", line 25, in __init__
    self._set_url(url)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\http\request\__init__.py", line 62, in _set_url
    raise ValueError('Missing scheme in request url: %s' % self._url)
ValueError: Missing scheme in request url: [
2018-12-02 23:34:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=4> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=3)
2018-12-02 23:34:39 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 23:34:39 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 23:34:40 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 23:43:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 23:43:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 23:43:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 23:43:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 23:43:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 23:43:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 23:43:41 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-02 23:43:41 [scrapy.core.engine] INFO: Spider opened
2018-12-02 23:43:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:43:41 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 23:43:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 23:43:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:43:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:43:56 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 23:43:56 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 23:43:58 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 23:45:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 23:45:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 23:45:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 1, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 23:45:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 23:45:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 23:45:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 23:45:28 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-02 23:45:28 [scrapy.core.engine] INFO: Spider opened
2018-12-02 23:45:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:45:28 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 23:45:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 23:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:45:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:45:46 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 23:45:46 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 23:45:48 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 23:45:48 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://38.103.161.131/forum/attachment.php?aid=3167114. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2018-12-02 23:45:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://38.103.161.131/forum/attachment.php?aid=3167114> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>, <twisted.python.failure.Failure twisted.web.http._DataLoss: >]
2018-12-02 23:47:27 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 23:47:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 23:47:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 2, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 23:47:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 23:47:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 23:47:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 23:47:27 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-02 23:47:27 [scrapy.core.engine] INFO: Spider opened
2018-12-02 23:47:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:47:27 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 23:47:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 23:47:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326545&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:47:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326587&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:47:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=2> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:47:47 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 23:47:47 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 23:47:48 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 23:54:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 23:54:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 23:54:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 45, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 23:54:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 23:54:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 23:54:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 23:54:56 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-02 23:54:56 [scrapy.core.engine] INFO: Spider opened
2018-12-02 23:54:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:54:56 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 23:54:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 23:55:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:55:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326591&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:55:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326589&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:55:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326587&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:55:49 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 23:55:50 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 23:55:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326541&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:55:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326545&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:55:50 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 23:55:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://38.103.161.131/forum/viewthread.php?tid=10326537&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-12-02 23:56:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-02 23:56:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-02 23:56:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 45, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-02 23:56:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 23:56:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 23:56:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 23:56:47 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-02 23:56:47 [scrapy.core.engine] INFO: Spider opened
2018-12-02 23:56:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:56:47 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-02 23:57:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-02 23:57:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:57:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 23:57:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326591&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326589&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-02 23:57:59 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-02 23:57:59 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-02 23:58:01 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-02 23:58:03 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://38.103.161.131/forum/viewthread.php?tid=10326545&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2018-12-02 23:58:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://38.103.161.131/forum/viewthread.php?tid=10326545&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>, <twisted.python.failure.Failure twisted.web.http._DataLoss: Chunked decoder in 'BODY' state, still expecting more data to get to 'FINISHED' state.>]
2018-12-03 00:02:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-03 00:02:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-03 00:02:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 45, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-03 00:02:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-03 00:02:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-03 00:02:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-03 00:02:33 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-03 00:02:33 [scrapy.core.engine] INFO: Spider opened
2018-12-03 00:02:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-03 00:02:33 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-03 00:02:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-03 00:02:48 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-03 00:02:49 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-03 00:02:50 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-03 00:02:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-12-03 00:02:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://38.103.161.131/forum/viewthread.php?tid=10326591&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2018-12-03 00:04:35 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-03 00:04:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-03 00:04:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 45, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-03 00:04:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-03 00:04:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-03 00:04:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-03 00:04:35 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-03 00:04:35 [scrapy.core.engine] INFO: Spider opened
2018-12-03 00:04:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-03 00:04:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-03 00:04:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-03 00:04:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:04:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326591&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:05:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326589&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:05:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326587&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:05:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326545&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:05:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326541&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:05:31 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-03 00:05:32 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-03 00:05:32 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-03 00:11:26 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-03 00:11:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-03 00:11:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 45, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-03 00:11:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-03 00:11:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-03 00:11:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-03 00:11:27 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-03 00:11:27 [scrapy.core.engine] INFO: Spider opened
2018-12-03 00:11:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-03 00:11:27 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-03 00:11:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-03 00:11:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326591&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:11:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326589&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:12:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326545&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:12:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326587&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:12:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326539&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:12:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326541&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:12:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326537&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:12:27 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2018-12-03 00:12:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326533&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:12:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326536&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:12:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326530&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:12:49 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-03 00:12:50 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-03 00:12:51 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-03 00:12:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://38.103.161.131/forum/attachment.php?aid=3167112> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2018-12-03 00:17:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-03 00:17:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-03 00:17:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 45, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-03 00:17:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-03 00:17:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-03 00:17:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-03 00:17:35 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-03 00:17:35 [scrapy.core.engine] INFO: Spider opened
2018-12-03 00:17:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-03 00:17:35 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-03 00:17:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-03 00:17:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326591&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:18:02 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-03 00:18:02 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-03 00:18:03 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-03 00:18:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://38.103.161.131/forum/viewthread.php?tid=10326589&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-12-03 00:19:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-03 00:19:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-03 00:19:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 45, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-03 00:19:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-03 00:19:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-03 00:19:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-03 00:19:53 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-03 00:19:53 [scrapy.core.engine] INFO: Spider opened
2018-12-03 00:19:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-03 00:19:53 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-03 00:19:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-03 00:20:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:20:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326591&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:20:28 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-03 00:20:28 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-03 00:20:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326589&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:20:29 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-03 00:20:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://38.103.161.131/forum/viewthread.php?tid=10326587&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-12-03 00:22:43 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-03 00:22:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-03 00:22:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 45, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-03 00:22:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-03 00:22:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-03 00:22:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-03 00:22:43 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-03 00:22:43 [scrapy.core.engine] INFO: Spider opened
2018-12-03 00:22:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-03 00:22:43 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-03 00:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-03 00:22:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:23:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326591&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:23:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326589&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:23:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326545&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:23:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://38.103.161.131/forum/viewthread.php?tid=10326591&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PythonWorkSpace\sis\sis\spiders\sisSpider.py", line 31, in parse_detail
    name = response.xpath("//div[@class='postmessage defaultpost']/h2/text()").extract()[0]
IndexError: list index out of range
2018-12-03 00:23:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326587&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:23:20 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-03 00:23:20 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-03 00:23:20 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-03 00:24:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: sis)
2018-12-03 00:24:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 13:35:33) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.15063-SP0
2018-12-03 00:24:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sis', 'CONCURRENT_REQUESTS': 45, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'LOG_FILE': 'sis.log', 'NEWSPIDER_MODULE': 'sis.spiders', 'SPIDER_MODULES': ['sis.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}
2018-12-03 00:24:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-03 00:24:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['sis.middlewares.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-03 00:24:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-03 00:24:33 [scrapy.middleware] INFO: Enabled item pipelines:
['sis.pipelines.DownloadImagesPipeline']
2018-12-03 00:24:33 [scrapy.core.engine] INFO: Spider opened
2018-12-03 00:24:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-03 00:24:33 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-03 00:24:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1> (referer: None)
2018-12-03 00:24:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326593&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:24:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326591&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:25:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326589&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:25:08 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-03 00:25:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-03 00:25:09 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-03 00:25:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://38.103.161.131/forum/viewthread.php?tid=10326587&extra=page%3D1%26amp%3Bfilter%3Dtype%26amp%3Btypeid%3D76> (referer: http://38.103.161.131/forum/forumdisplay.php?fid=25&filter=type&typeid=76&page=1)
2018-12-03 00:25:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sehuatuchuang.com/images/2018/12/02/QQ20181130174122.jpg> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-12-03 00:25:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sehuatuchuang.com/images/2018/12/02/QQ20181130174230.jpg> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-12-03 00:25:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sehuatuchuang.com/images/2018/12/02/QQ20181130174259.jpg> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
